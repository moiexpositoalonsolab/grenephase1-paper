{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccb9eb27-ea38-419b-a434-29059ecb0963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import pickle\n",
    "import dask.dataframe as dd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import random\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "187f35de-a745-400e-aa66-ee894df35d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import allel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04e27bc4-fc05-4f31-bae0-89dbbc943872",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check that the order of ecotypes in the vcf and in the ecotype freq file is the same \n",
    "#import allel\n",
    "## ld pruned vcf file\n",
    "#vcf_file = '/carnegie/nobackup/scratch/xwu/grenet/hapFIRE_updatedVCF/greneNet_final_v1.1.recode.vcf'\n",
    "#vcf = allel.read_vcf(vcf_file)\n",
    "\n",
    "#ecotypes_names1 = vcf['samples']\n",
    "\n",
    "#ecotypes_names2 = pd.read_csv('/carnegie/nobackup/scratch/xwu/grenet/ecotypes_names.txt',header=None)\n",
    "\n",
    "#ecotypes_names1 == np.array(ecotypes_names2[0]).astype(str)\n",
    "\n",
    "#gen = vcf['calldata/GT']\n",
    "\n",
    "#gen.shape\n",
    "\n",
    "#gen = gen.sum(axis=2)\n",
    "\n",
    "#(genotype_counts.values == gen).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f1eec1-5b44-4980-bcb2-aa0098eeea25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6a1e36-d576-4a50-b06c-a7c6f7865bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31cf347b-7ea6-4bda-8f97-cb0c8acf961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_file = '/carnegie/nobackup/scratch/xwu/grenet/hapFIRE_updatedVCF/greneNet_final_v1.1_LDpruned.recode.vcf'\n",
    "vcf = allel.read_vcf(vcf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e158669-4a0c-4d34-8a5d-7d1a089d8889",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = vcf['samples']\n",
    "samples = samples.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd1e97e0-9bc2-41df-a20f-28c9bd87ab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bring the founder \n",
    "af_founder = pd.read_csv('../leave_1_out/af_founder.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73c1a2e5-c8fe-4887-b9b8-a733bbfa5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delta_p_file = 'delta_p.csv'\n",
    "#delta_p = dd.read_csv(delta_p_file, sep = ',')\n",
    "\n",
    "#delta_p = delta_p.compute() \n",
    "\n",
    "#delta_p = delta_p.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71a1e6e9-4f7c-46f3-927f-61534914a49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genotype_counts = pd.read_csv('genotype_counts_fullgenome231ecotypes.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9818492-7e76-410e-880e-184ebd018e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ter = pd.read_csv('../final_gen.csv')['sample_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be5d702a-fc18-47a0-9f11-2844d7196f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DELTA ECOTYPE FREQ\n",
    "#path_ecotypes = '/carnegie/nobackup/scratch/xwu/grenet/merged_frequency/merged_ecotype_frequency.txt'\n",
    "real_ef = pd.read_csv('../delta_ecotype_freq.txt',sep = '\\t', usecols = final_ter)\n",
    "real_ef.index = samples\n",
    "real_ef.index = real_ef.index.astype(int)\n",
    "real_ef.columns = pd.Series(real_ef.columns).str.split('_').str[0] + '_' + pd.Series(real_ef.columns).str.split('_').str[2]\n",
    "\n",
    "\n",
    "\n",
    "######################\n",
    "## P1/P0 ECOTYPE FREQ\n",
    "real_ef=pd.read_csv('stabilizing_selection_data_scaled_2024Jun18.txt', sep = '\\t')[['log_p1_p0','ecotype', 'site','plot']]\n",
    "real_ef['sample'] = real_ef['site'].astype(str) + '_' + real_ef['plot'].astype(str) \n",
    "real_ef['p1_over_p0'] = np.exp(real_ef['log_p1_p0'])\n",
    "real_ef = real_ef.drop(['log_p1_p0', 'site', 'plot'],axis=1)\n",
    "real_ef = real_ef.pivot_table(index = 'ecotype', columns = 'sample', values='p1_over_p0')\n",
    "real_ef.index = real_ef.index.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99e20837-5c87-4dd5-993f-c0bde491362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ecotype_terminal_frequencies_wide = pd.read_csv('ecotype_terminal_frequencies_wide.csv').drop('Unnamed: 0',axis=1)\n",
    "\n",
    "#ecotype_terminal_frequencies_wide = ecotype_terminal_frequencies_wide.set_index('site_rep').T\n",
    "\n",
    "#ecotype_terminal_frequencies_wide.index = ecotype_terminal_frequencies_wide.index.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72248538-acc3-4d20-ac39-fe71fbc0b122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6fc621f-4a6c-4a2a-8c57-7ba448d0a72f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For positive infinity\n",
    "#real_ef[np.isposinf(np.exp(real_ef['log_p1_p0']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f06436-4397-404d-bd73-bc878b1c9f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bace49f-d871-428a-a342-8e4b1f105a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv('ecotype_terminal_frequencies_wide.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e44a075-db3e-4c39-9ccc-78775fc16516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c77a18df-f68c-400b-89b3-3ba87e71822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_ecotypes = '../stabilizing_selection_data.txt'\n",
    "\n",
    "#real_ef = pd.read_csv(path_ecotypes, sep = '\\t') #,usecols = final_gen)\n",
    "#unique_sites = real_ef['site'].unique()\n",
    "#real_ef['sample'] = real_ef['site'].astype(str) + '_' + real_ef['plot'].astype(str) \n",
    "#real_ef = real_ef[['log_p1_p0', 'ecotype', 'sample']]\n",
    "#real_ef = real_ef.drop(real_ef[real_ef['log_p1_p0'] == -np.inf].index)\n",
    "#real_ef = real_ef.pivot_table(index = 'ecotype', columns = 'sample', values='log_p1_p0')\n",
    "#real_ef.index = real_ef.index.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aef8e28-9980-4c23-9a12-9a1709dd45e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f13dcb-94dc-4486-8186-c9dc3c55deaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d0b4081-6000-465e-bf2b-82d1c140728b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('splits_samples.pkl', 'rb') as file:\n",
    "    splits_samples = pickle.load(file)\n",
    "\n",
    "len(splits_samples) ## 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e621ff8-b97b-4798-8b80-f4780c320aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(directory, filename):\n",
    "    \"\"\"\n",
    "    Search for files with a specific name within all subdirectories of a given directory.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): The root directory from which to start the search.\n",
    "        filename (str): The name of the file to search for.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of full paths to the files that match the given filename.\n",
    "    \"\"\"\n",
    "    matches = []  # List to store the full paths of matching files\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if filename in files:\n",
    "            full_path = os.path.join(root, filename)\n",
    "            matches.append(full_path)\n",
    "    return matches\n",
    "\n",
    "# Usage example\n",
    "root_directory = '/carnegie/nobackup/scratch/tbellagio/gea_grene-net/leave_1_out/'  # Update this to the directory you want to search\n",
    "target_filename = 'predicted_delta_p_bio1.csv'\n",
    "predicted_delta_p_bio1_files = find_files(root_directory, target_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c05c2c9-099d-4397-af8c-2878f0daaa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "root_directory = '/carnegie/nobackup/scratch/tbellagio/gea_grene-net/leave_1_out/'  # Update this to the directory you want to search\n",
    "target_filename = 'snps_indices_bio1.csv'\n",
    "snps_indices_bio1_files = find_files(root_directory, target_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d516ceee-67f7-47e8-8ae8-983d87353a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "founder_ef = pd.read_csv('/carnegie/nobackup/scratch/xwu/grenet/merged_frequency/ecotype_founder_frequency.txt', header=None)\n",
    "founder_ef.index = samples\n",
    "founder_ef.index = founder_ef.index.astype(int)\n",
    "founder_ef_series = founder_ef.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94f08aaa-8cd9-49bc-8b5d-13e8c661dab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rpos_index0_file = f'/carnegie/nobackup/scratch/tbellagio/gea_grene-net/leave_1_out/split_number_{split_number}/delta_p/dict_rpos_index0.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2c1e3e1-9aee-4c6a-8283-7aa2501d3535",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the dictionary with the index0 and real snp id\n",
    "with open(dict_rpos_index0_file, 'rb') as file:\n",
    "    dict_rpos_index0 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7811382-f490-45ab-a837-885776667c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_rpos_index0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c5ab8602-cdfa-4f45-9c4f-0ee475a76f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_number = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "389c41fd-4e9e-461c-a0a5-25a82419318d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n",
      "477\n",
      "331\n",
      "105\n",
      "12\n",
      "94\n",
      "44\n",
      "159\n",
      "152\n",
      "17\n",
      "79\n",
      "327\n",
      "64\n",
      "97\n",
      "89\n",
      "116\n",
      "115\n",
      "113\n",
      "133\n",
      "459\n",
      "53\n",
      "45\n",
      "191\n",
      "30\n",
      "186\n",
      "219\n",
      "87\n",
      "613\n",
      "342\n",
      "229\n",
      "33\n",
      "232\n",
      "242\n",
      "209\n",
      "67\n",
      "25\n",
      "57\n",
      "54\n",
      "14\n",
      "100\n",
      "33\n",
      "252\n",
      "497\n",
      "150\n",
      "91\n",
      "85\n",
      "49\n",
      "111\n",
      "215\n",
      "119\n",
      "282\n",
      "213\n",
      "203\n",
      "114\n",
      "536\n",
      "284\n",
      "155\n",
      "209\n",
      "217\n",
      "46\n",
      "207\n",
      "449\n",
      "228\n",
      "50\n",
      "70\n",
      "253\n",
      "188\n",
      "111\n",
      "31\n",
      "458\n",
      "49\n",
      "107\n",
      "14\n",
      "171\n",
      "121\n",
      "220\n",
      "38\n",
      "115\n",
      "153\n",
      "70\n",
      "175\n",
      "108\n",
      "402\n",
      "279\n",
      "336\n",
      "162\n",
      "71\n",
      "98\n",
      "298\n",
      "106\n",
      "404\n",
      "89\n",
      "793\n",
      "251\n",
      "382\n",
      "192\n",
      "220\n",
      "106\n",
      "121\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "for split_number in range(100):\n",
    "    ## import the predicted delta_p for bio 1 (climate*estimated_beta)\n",
    "    predicted_delta_p_bio1_file = f'/carnegie/nobackup/scratch/tbellagio/gea_grene-net/leave_1_out/split_number_{split_number}/delta_p/predicted_allele_freq_bio1.csv'\n",
    "    ## import the indices of the snps significantly associated identified by lfmm \n",
    "    snps_indices_bio1_file = f'/carnegie/nobackup/scratch/tbellagio/gea_grene-net/leave_1_out/split_number_{split_number}/delta_p/snps_indices_bio1.csv'\n",
    "    ## clumping file \n",
    "    clumping_file = f'/carnegie/nobackup/scratch/tbellagio/gea_grene-net/leave_1_out/split_number_{split_number}/delta_p/output_clumping02.clumped'\n",
    "    \n",
    "    genomic_offset_file = f'/carnegie/nobackup/scratch/tbellagio/gea_grene-net/leave_1_out/split_number_{split_number}/delta_p/pos_genomic_offset.csv'\n",
    "    #output_file_efpredr2 = f'/carnegie/nobackup/scratch/tbellagio/gea_grene-net/leave_1_out/split_number_{split_number}/delta_p/r2fit_pred_ecotype_freq.csv' \n",
    "    dict_rpos_index0_file = f'/carnegie/nobackup/scratch/tbellagio/gea_grene-net/leave_1_out/split_number_{split_number}/delta_p/dict_rpos_index0.pkl'\n",
    "    ## load the dictionary with the index0 and real snp id\n",
    "    with open(dict_rpos_index0_file, 'rb') as file:\n",
    "        dict_rpos_index0 = pickle.load(file)\n",
    "    \n",
    "    output_file_sp = f'/carnegie/nobackup/scratch/tbellagio/gea_grene-net/leave_1_out/split_number_{split_number}/delta_p/spcorr_pred_ecotype_freq.csv' \n",
    "    ## export the acutal prediction of ecotype freq \n",
    "    output_file_pred_ef = f'/carnegie/nobackup/scratch/tbellagio/gea_grene-net/leave_1_out/split_number_{split_number}/delta_p/pred_ecotype_freq.csv' \n",
    "    \n",
    "    # get the train and split samples for this split\n",
    "    train_samples = splits_samples[split_number][0]\n",
    "    test_samples = splits_samples[split_number][1]\n",
    "    \n",
    "    # import the predicted delta_p for bio 1 (climate*estimated_beta)\n",
    "    predicted_delta_p_bio1 = pd.read_csv(predicted_delta_p_bio1_file).drop('Unnamed: 0',axis=1)\n",
    "    \n",
    "    snps_indices_bio1_old = pd.read_csv(snps_indices_bio1_file)\n",
    "    \n",
    "    ## check if any association was found, if not skip\n",
    "    if len(snps_indices_bio1_old) == 0:\n",
    "        print(f'No snps split {split_number}')\n",
    "    else:  \n",
    "    \n",
    "        # load the result of clumping\n",
    "        clumping = pd.read_csv(clumping_file, delim_whitespace=True)\n",
    "        # use the dictionary to get a column with the index of the clumped snps \n",
    "        clumping['index0'] = clumping['SNP'].replace(dict_rpos_index0)\n",
    "    \n",
    "        ## now retrieve the index based 0 for the selected snps \n",
    "        snps_0index = clumping['index0']\n",
    "        snps_0index = snps_0index.to_list()\n",
    "        print(len(snps_0index))\n",
    "    \n",
    "        ## retrieving the old index to filter the allele freq prediciton\n",
    "        snps_1index = np.array(snps_0index) + 1\n",
    "    \n",
    "        ## take from the singificant indices the ones tahs passed the clumping \n",
    "        snps_indices_bio1_old = snps_indices_bio1_old[snps_indices_bio1_old['x'].isin(snps_1index)]\n",
    "        \n",
    "        predicted_delta_p_bio1.columns = predicted_delta_p_bio1.columns.str.replace('V','').astype(int)\n",
    "        \n",
    "        # the first co.umn is the index of the dataframe onlu containign the significant snps \n",
    "        # the second column are the indexed of the full genome (1 indexed)\n",
    "        snps_indices_bio1_old.columns = ['old_index1short', 'snps_indices_bio1_old_full']\n",
    "        \n",
    "        ## filter based on the frist column, because thats ithe actual index \n",
    "        predicted_delta_p_bio1 = predicted_delta_p_bio1[snps_indices_bio1_old['old_index1short']]\n",
    "            \n",
    "        \n",
    "        predicted_delta_p_bio1t = predicted_delta_p_bio1.T\n",
    "        \n",
    "        predicted_delta_p_bio1t.index = snps_0index\n",
    "        predicted_delta_p_bio1t.columns = test_samples\n",
    "        \n",
    "        ## filter the af of the founder onyl for the selected snps \n",
    "        af_founder_sel = af_founder.iloc[snps_0index] \n",
    "        af_founder_sel = np.array(af_founder_sel['af'])\n",
    "    \n",
    "        # calcualte the actual precited allele freq (not the delta) to use in the ecotype estimation \n",
    "    \n",
    "        \n",
    "        ## get the genotype counts matrix only with the selected snps \n",
    "        genotype_counts_filt = genotype_counts.iloc[snps_0index, :]\n",
    "        genotype_counts_array = genotype_counts_filt.to_numpy()\n",
    "        \n",
    "        pos_genomic_offsets = {}\n",
    "        for sample in predicted_delta_p_bio1t.columns:\n",
    "            sample_coefficients = np.array(predicted_delta_p_bio1t[sample]).reshape(-1,1)\n",
    "            genomic_offset = np.sum(sample_coefficients * genotype_counts_array, axis=0)\n",
    "            pos_genomic_offsets[sample] = genomic_offset\n",
    "        \n",
    "        pos_genomic_offsets = pd.DataFrame(pos_genomic_offsets)\n",
    "        \n",
    "        pos_genomic_offsets.index = samples\n",
    "        \n",
    "        pos_genomic_offsets.to_csv(genomic_offset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a166082-92c1-4a95-8ada-0f9adaabe87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_number in range(100):\n",
    "    genomic_offset_file = f'/carnegie/nobackup/scratch/tbellagio/gea_grene-net/leave_1_out/split_number_{split_number}/delta_p/pos_genomic_offset.csv'\n",
    "    genomic_offset_results_file = f'/carnegie/nobackup/scratch/tbellagio/gea_grene-net/leave_1_out/split_number_{split_number}/delta_p/genomic_offset_results.csv'\n",
    "    \n",
    "    genomic_offset_file = pd.read_csv(genomic_offset_file).set_index('Unnamed: 0')\n",
    "    \n",
    "    genomic_offset_file.columns = pd.Series(genomic_offset_file.columns).str.split('_').str[0] + '_' + pd.Series(genomic_offset_file.columns).str.split('_').str[2]\n",
    "    \n",
    "    # get the train and split samples for this split\n",
    "    test_samples = splits_samples[split_number][1]\n",
    "    real_ef_test = real_ef[genomic_offset_file.columns]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for i in genomic_offset_file.columns:\n",
    "        both = pd.concat([real_ef_test[i], genomic_offset_file[i]],axis=1)\n",
    "        both.columns = ['real', 'pred']\n",
    "    \n",
    "        #spearman \n",
    "        sp_correlation, _ = spearmanr(both['real'], both['pred'])\n",
    "    \n",
    "        # pearson\n",
    "        pearsonr_value = pearsonr(both['real'], both['pred'])[0]\n",
    "    \n",
    "        ## r2\n",
    "        X = both['real'].values.reshape(-1, 1)  # Independent variable\n",
    "        y =  both['pred'].values \n",
    "        model = LinearRegression().fit(X, y)\n",
    "        y_pred = model.predict(X)\n",
    "        \n",
    "        r_squared = r2_score(y, y_pred)\n",
    "        \n",
    "        results[i] = [sp_correlation, pearsonr_value, r_squared]\n",
    "        \n",
    "    results = pd.DataFrame(results).T\n",
    "    results.columns = ['sp_correlation', 'pearsonr', 'r_squared']\n",
    "    \n",
    "    results.to_csv(genomic_offset_results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85bffc6-285e-4e37-b3db-dd51c451b95c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5946c4fd-218d-4ff2-bdb3-b93f998c50e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pipeline_snakemake)",
   "language": "python",
   "name": "pipeline_snakemake"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
